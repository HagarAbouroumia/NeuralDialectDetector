adam_epsilon: 1.0e-08
batch_size: 16
bottleneck_dim: 384
checkpoint_on_improvement: true
checkpointing_freq: 20
checkpointing_on: false
checkpointing_path: checkpoints_4
classif_dropout_rate: 0.3
current_adapter_to_train: 20
device: cuda
early_stopping: true
early_stopping_patience: 10
improvement_check_freq: 50
initial_learning_rate: 0.000275
masking_percentage: 0.2
model_class: ArabicDialectBERTMaskedLM
model_name_path: checkpoints_4/adapter_fusion_Mauritania
neptune_experiment_name: Libya_adapter_fusion_stage_1
neptuneaiAPI: eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiYzNlOTI4MDUtMWEwMC00N2U3LWEzYTAtZjAyMzA2YzE1YjI3In0=
no_total_adapters: 21
num_epochs: 100
one_class_filtration: Libya
path_to_data: NADI2021_DEV.1.0/NADI2021_DEV.1.0/Subtask_1.2+2.2_DA
run_title: adapter_fusion_Libya
save_final_model: true
seed_list:
- 1033
- 611
- 520
- 300
- 760
stage_2_training: false
use_adapt_after_fusion: false
use_adapters: true
warmup_steps: 0
